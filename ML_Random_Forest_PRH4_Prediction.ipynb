{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f63d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 4 - ML Random Forest Algorithm for PRH4 Prediction for Customer's next Order\n",
    "# Introduction:\n",
    "# This script performs data preprocessing and machine learning model training using a sales dataset.\n",
    "# The main objective is to predict the 'PRH4' category based on features such as sales channel, customer group, customer number, region, and DSO Indicator.\n",
    "# The script involves the following steps:\n",
    "# 1. Importing necessary libraries.\n",
    "# 2. Loading the dataset and cleaning it by removing customers with null values.\n",
    "# 3. Filtering customers based on specific criteria related to unique orders and PRH4 categories.\n",
    "# 4. Splitting the data into training and testing sets.\n",
    "# 5. One-hot encoding the categorical features.\n",
    "# 6. Training a Random Forest Classifier model.\n",
    "# 7. Evaluating the model using accuracy, precision, recall, and F1 score.\n",
    "# 8. Displaying the maximum depth of the trained Random Forest model's trees.\n",
    "\n",
    "# Summary:\n",
    "# The script successfully cleans the dataset by removing customers with null values and those who don't meet specific criteria.\n",
    "# The Random Forest Classifier model is trained and evaluated on the cleaned dataset.\n",
    "# The model achieves an accuracy of 50.21%, precision of 47.65%, recall of 50.21%, and F1 score of 47.03%.\n",
    "# The maximum depth of the trees in the Random Forest model is found to be 655, indicating deep and complex trees.\n",
    "# This performance suggests that while the model captures some patterns in the data, further tuning and feature engineering may be required to improve its predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a908029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1c4043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/w5x9js51325d0gtv9ldxkd8c0000gn/T/ipykernel_93728/1782254944.py:3: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in the final_cleaned_df DataFrame: 94995\n",
      "The number of unique customers in the final_cleaned_df DataFrame: 5003\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Client Data/MergedCSV/MergedData.csv'\n",
    "merged_df = pd.read_csv(file_path)\n",
    "\n",
    "# Identify customers with any NULL values in any column\n",
    "customers_with_nulls = merged_df[merged_df.isnull().any(axis=1)]['customer_number'].unique()\n",
    "\n",
    "# Remove all records of these customers from the dataset\n",
    "cleaned_df = merged_df[~merged_df['customer_number'].isin(customers_with_nulls)]\n",
    "\n",
    "# Calculate the unique order count for each customer\n",
    "unique_orders_per_customer = cleaned_df.groupby('customer_number')['order_number'].nunique()\n",
    "\n",
    "# Identify customers who have placed more than 3 unique orders\n",
    "customers_with_more_than_3_orders = unique_orders_per_customer[unique_orders_per_customer > 2].index\n",
    "\n",
    "# Filter the cleaned_df to keep only those customers\n",
    "filtered_cleaned_df = cleaned_df[cleaned_df['customer_number'].isin(customers_with_more_than_3_orders)]\n",
    "\n",
    "# Calculate the number of unique PRH4 per order\n",
    "unique_prh4_per_order = filtered_cleaned_df.groupby(['order_number', 'customer_number'])['PRH4'].nunique()\n",
    "\n",
    "# Identify customers who have ordered more than 7 unique PRH4 in the same order\n",
    "customers_with_more_than_7_prh4 = unique_prh4_per_order[unique_prh4_per_order >= 7].index.get_level_values('customer_number').unique()\n",
    "\n",
    "# Remove all records of these customers from the filtered_cleaned_df\n",
    "final_cleaned_df = filtered_cleaned_df[~filtered_cleaned_df['customer_number'].isin(customers_with_more_than_7_prh4)]\n",
    "\n",
    "# Display the number of records in the final cleaned dataset\n",
    "num_records_final_cleaned = final_cleaned_df.shape[0]\n",
    "print(f'The number of records in the final_cleaned_df DataFrame: {num_records_final_cleaned}')\n",
    "\n",
    "# Check the number of unique customers in the final cleaned dataframe\n",
    "unique_customers_final_cleaned = final_cleaned_df['customer_number'].nunique()\n",
    "print(f'The number of unique customers in the final_cleaned_df DataFrame: {unique_customers_final_cleaned}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98e21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_cleaned_df\n",
    "\n",
    "# Define the feature columns and the target column\n",
    "feature_columns = ['sales_channel', 'customer_group', 'customer_number', 'region', 'DSO_Ind']\n",
    "target_column = 'PRH4'\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), feature_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X = column_transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "# Total number of records\n",
    "total_records = len(df)\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(total_records * 0.8)\n",
    "\n",
    "\n",
    "X_train = X[:split_index]\n",
    "X_test = X[split_index:]\n",
    "y_train = y[:split_index]\n",
    "y_test = y[split_index:]\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16bf64bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sachin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sachin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.502131691141639\n",
      "Precision: 0.47654466658314026\n",
      "Recall: 0.502131691141639\n",
      "F1 Score: 0.4703046100633046\n",
      "Classification Report:\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "           Abutments, Customizable       0.00      0.00      0.00         5\n",
      "             Abutments, Edentulous       0.36      0.18      0.24       432\n",
      "                    Abutments, SRA       0.35      0.09      0.14       825\n",
      "                Abutments, Ti Base       0.63      0.43      0.51       492\n",
      "  Abutments, single tooth + bridge       0.54      0.24      0.33       207\n",
      "        Allogenic Bone Substitutes       0.29      0.33      0.31       271\n",
      "      Allogenic Soft Tissue Grafts       0.00      0.00      0.00        13\n",
      "               BL Healing Surgical       0.39      0.20      0.27      2179\n",
      "     BLAT Ti Implants, hydrophilic       0.57      0.77      0.66      1684\n",
      "        BLAT Ti Implants, standard       0.63      0.64      0.64      1574\n",
      "   BLAT TiZr Implants, hydrophilic       0.44      0.32      0.37       840\n",
      "BLAT TiZr Implants, hydrophilic TF       0.00      0.00      0.00        28\n",
      "      BLAT TiZr Implants, standard       0.48      0.51      0.50       484\n",
      "     BLFT Ti Implants, hydrophilic       0.30      0.35      0.32        40\n",
      "        BLFT Ti Implants, standard       0.22      0.09      0.13        54\n",
      "BLFT TiZr Implants, hydrophilic TF       0.42      0.50      0.46       672\n",
      "   BLFT TiZr Implants, standard TF       0.42      0.38      0.40       171\n",
      "     BLPW Ti Implants, hydrophilic       0.00      0.00      0.00         5\n",
      "        BLPW Ti Implants, standard       0.17      0.17      0.17         6\n",
      "   BLPW TiZr Implants, hydrophilic       0.43      0.63      0.51       104\n",
      "      BLPW TiZr Implants, standard       0.60      0.35      0.44        52\n",
      "                            Blocks       0.00      0.00      0.00         3\n",
      "              Ceramic Implants, BL       0.67      0.36      0.47        11\n",
      "              Ceramic Implants, TL       0.38      0.45      0.42        11\n",
      "                    Collagen Plugs       1.00      0.22      0.36         9\n",
      "              Consumables, Liquids       0.44      0.15      0.23        26\n",
      "                           Copings       0.15      0.03      0.05       101\n",
      "                Customer Education       0.00      0.00      0.00         5\n",
      "      Digital Accessories + Others       0.34      0.20      0.25        50\n",
      "                          Emdogain       0.65      0.49      0.56       136\n",
      "     Instruments + Auxiliaries GBR       0.25      0.06      0.09        35\n",
      "       Instruments, Cases + Others       0.44      0.39      0.42      1525\n",
      "        Instruments, Drills + Taps       0.39      0.30      0.34       820\n",
      "                IntraOral Hardware       0.10      0.03      0.04        37\n",
      "          Local 3rd Party Products       0.28      0.22      0.24        88\n",
      "            Miscellaneous + Others       0.00      0.00      0.00        10\n",
      "                    Other Implants       1.00      0.33      0.50         3\n",
      "                 Other Prosthetics       0.54      0.79      0.64      5112\n",
      "       Other Restorative Solutions       0.41      0.43      0.42       502\n",
      "                    Other Services       0.00      0.00      0.00         1\n",
      "          Other Software + License       0.00      0.00      0.00         2\n",
      "        Porcine Collagen Membranes       0.37      0.12      0.18       109\n",
      "                              SRBB       0.00      0.00      0.00         6\n",
      "       Surgical Equipment + Others       0.00      0.00      0.00         1\n",
      "        Surgical Planning Services       0.44      0.39      0.42        28\n",
      "        Synthetic Bone Substitutes       0.00      0.00      0.00         5\n",
      "               TL Healing Surgical       0.06      0.03      0.04        65\n",
      "     TLAT Ti Implants, hydrophilic       0.00      0.00      0.00         1\n",
      "TLAT TiZr Implants, hydrophilic TF       0.00      0.00      0.00         1\n",
      "TLFT TiZr Implants, hydrophilic TF       0.00      0.00      0.00        14\n",
      "   TLFT TiZr Implants, standard TF       0.00      0.00      0.00         2\n",
      "        TLPW Ti Implants, standard       0.45      0.83      0.59         6\n",
      "   TLPW TiZr Implants, hydrophilic       0.18      0.21      0.19        28\n",
      "      TLPW TiZr Implants, standard       0.67      0.14      0.24        14\n",
      "        Xenogenic Bone Substitutes       0.15      0.31      0.20        29\n",
      "                Zygomatic Implants       0.39      0.14      0.20        65\n",
      "\n",
      "                          accuracy                           0.50     18999\n",
      "                         macro avg       0.30      0.23      0.24     18999\n",
      "                      weighted avg       0.48      0.50      0.47     18999\n",
      "\n",
      "Hyperparameters:\n",
      "n_estimators: 100\n",
      "max_depth: None\n",
      "min_samples_split: 2\n",
      "min_samples_leaf: 1\n",
      "random_state: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model with specific hyperparameters\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,  # Number of trees in the forest\n",
    "    max_depth=None,    # Maximum depth of the tree\n",
    "    min_samples_split=2,  # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=1,   # Minimum number of samples required to be at a leaf node\n",
    "    random_state=42      # Seed used by the random number generator\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics and hyperparameters\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Display the hyperparameters\n",
    "print('Hyperparameters:')\n",
    "print(f'n_estimators: {model.n_estimators}')\n",
    "print(f'max_depth: {model.max_depth}')\n",
    "print(f'min_samples_split: {model.min_samples_split}')\n",
    "print(f'min_samples_leaf: {model.min_samples_leaf}')\n",
    "print(f'random_state: {model.random_state}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28e5d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth of the Random Forest model: 655\n"
     ]
    }
   ],
   "source": [
    "# Find the max depth of the trees in the forest\n",
    "max_depths = [estimator.tree_.max_depth for estimator in model.estimators_]\n",
    "max_depth = max(max_depths)\n",
    "\n",
    "# Display the max depth\n",
    "print(f'Max Depth of the Random Forest model: {max_depth}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
